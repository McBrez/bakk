%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                              %
%   File:     metholodgy.tex                                                   %
%   Document: XXX	                                                           %
%   Author:   Freismuth David                                                  %
%	Date:	  22.JUN.2018                                                      %
%   Content:  Contains the Metholodgy section of the Bachelor thesis.          %
%                                                                              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Metholodgy}

To achieve our goal of the categorization of hardware designs trough a structural
analysis of the corresponding HDL Design, we first propose a standardized 
match vector, which is calculated from the Design's Two-to-One and One-to-One Gate
Level Connections (see \label{logicGates} for referencce). The vector gets standardized,
so small designs remain compareable to bigger ones. This vector shall then act as 
categorization criteria, to sort the design into predefined design categories. 
Those categories are clusters in the vector space the match vector is part of. 
If the match vector points into such a cluster, the design is identified with the
corresponding category.
This section elaborates on the details of finding a match vector of a design, and
how the category clusters are defined. 

\subsection{Cluster Identification}
As mentionend above, before any categorization can take place, the categories itself
have to be defined. In our model, categories are clusters in a n-dimensional vector space. 
Therefore, the task is to identify clusters in this vector space, and name them. 
To do this, we determine the match vector of well known designs. Since
the categorization of those designs is already available, the vectors that originate from designs with identical categorizations, can be grouped together to clusters. 

It is expected, that the validity of such clusters increases with the number of analyzed designs. Therefore an automatic process has to be established, to enable the analysis of a great amount of designs. To achieve this, we use Scrapy, a Python web scraping tool, to 
automatically obtain design files and corresponding meta-information. \gls{oc}serves as source for those design files, and provides following information. 

\begin{enumerate}

	\item{\gls{url} to the compressed design archive}

	\item{The name of the design project}

	\item{The \gls{hdl} in which the design is specified and implemented}

	\item{The category in which a design is listed}
	
	\item{The \gls{hdl} files of the design}
	
\end{enumerate}
The following chapters explain in detail, how those informations are gathered, and processed into a match vector. 

\subsubsection{Scraping OpenCores project web sites} 
\gls{oc} does not offer an interface to automatically download all available design files. Therefore it has to be resorted to the web page, which is optimized for human interaction, but not for machine readability. Tools which are spezialized in translating human readable content into structured, machine oriented data sets, are called Scrapers. Scrapy is one of them, and provides multiple python classes which enable extensible web scraping. 

Scrapy's input is the HTML representation of the web page, which it is able to retrieve by itself. The HTML code is scanned for its tags, which are then exposed in python classes. Those python classes are available to the user.  


Like most web pages, \gls{oc} is built in a tree-like structure.  
The scraped data is temporarily stored into Python class objects. The information 
in these objects are written to a .JSON file, in order to make them persistent (such
that we do not have to scrape the entire \gls{oc} web site every time we use our 
classification framework). For this .JSON file, a specific format has been defined, 
so information can be imported from other sources then scrapy aswell. 

\begin{figure}[tb]
	\centering
	\includegraphics[width=\textwidth,keepaspectratio]{../pictures/jsonFileFormatDescription.JPG}
	\caption{.JSON File Format Description}
	\label{fig:jsonFormat}
\end{figure}

Figure \Cref{fig:jsonFormat} shows an example of the content of the .JSON file. 

\subsubsection{Downloading OpenCores projects}
The Scrapy python module provides the functionallity to automatically download and
store files that are associated with a Hardware design project, to a predefined
folder. Since \gls{oc} requires an account to be able to download hardware designs, 
we use a scrapy internal function to send a POST request to the \gls{oc} webpage,
in order to authorize ourselfs. 

Because all project files from the \gls{oc} database are provided as tar.gz archives,
we introduced an additional decompression step.  

\subsubsection{Decompressing design files} 
Projects from \gls{oc} are solely provided as *.tar.gz compressed archive. The \gls{python}
module tarfile enables the extraction of those archives. Additionally 
to the decompression, we sort the project files into folders corresponding to 
their associated hardware category (as stated by \gls{oc}). After that, the file 
endings of the files are analysed. If those endings indicate a \gls{hdl} file, the path 
to this file is added to the aforementioned .JSON file, in order to be able to
address the design files of a project in later steps.

\subsubsection{Reading designs into synthesis tool} 
After the design has been decompressed, it is time to let the synthesis tool 
yosys read the design files and synthesise them into a text file format. In 
order to do this, yosys expects a yosys script file, which holds all yosys commands 
that should be executed on a set of files. This script file can either be provided
by the user before a programm run, or a generic one can be generated automatically 
during a programm run, according to the files that have been provided with the 
.JSON file. 

The synthesis tool's frontend is chosen based on the language of each design file.
For \gls{vhdl} and SystemVerilog, the \lstinline{verific} frontend is used. For Verilog,
we use the \lstinline{read_verilog} frontend. Once any combination of \gls{hdl} files
has been loaded, a synthesize run attempts to generate a single HDL file from the provided
files, which solely contains primitive logic blocks. 

Since yosys does not support automatic dependency recognition of vhdl files, a custom solution
had to be found, to determine the load order of vhdl files (in the case that the user decides
that yosys scripts should be generated automatically). To accomplish this, we slightly modified 
the Vunit python project, which offers a function to return the \gls{vhdl} 
files in an ordered list. The vhdl files can then be loaded in the order dictated by this list.  

\subsubsection{Naming designs} 
Each design that is read by the synthesis tool is named after the project from
which the design files are downloaded. From then, the design name is the main
reference for each design and serves as identification feature in all
subsequent steps.

\subsubsection{Matching designs against standard pattern vector}
\subsubsection{Calculating clusters of design match vectors}

\subsection{Design Identification}
blabla

\subsection{Verification}
blabla



